{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UUmnTuL98gDV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.io import read_image\n",
        "import os\n",
        "import h5py\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, in_channels=1, dim=64, img_size=100):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.img_size = img_size\n",
        "        # Define the encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, dim, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.fc = nn.Linear(dim * (img_size // 4)**2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = self.encoder(x)  # [batch, time, in_channels, size, size] -> [batch, time, dim, size/4, size/4]\n",
        "        x = x.view(-1, self.dim * (self.img_size // 4)**2)  # Adjust the product based on your image size\n",
        "        out = self.fc(x)\n",
        "        return out.unsqueeze(-1)\n",
        "        \n",
        "        \n",
        "\n",
        "class ImageWeights(nn.Module):\n",
        "    def __init__(self, in_dim, dim, img_size, device):\n",
        "        super(ImageWeights, self).__init__()\n",
        "        # img_size is the multiplication of width and height\n",
        "        # Define convolutional layers\n",
        "        self.device = device\n",
        "        self.img_size = img_size\n",
        "        self.Fextractor = FeatureExtractor(in_channels=in_dim*2, dim=dim, img_size=img_size)\n",
        "\n",
        "    def forward(self, l8co, s2_series, mask):\n",
        "        # l8co = [batch_num, channel, height, width] (300*300)\n",
        "        # s2_series = [batch_num, series_len, channel, height, width]\n",
        "        # mask = [batch_num, series_len], type: numpy\n",
        "        # assume the input images' height equal to widths\n",
        "        scale_l8 = l8co.shape[-1] / self.img_size\n",
        "        scale_s2 = s2_series.shape[-1] / self.img_size\n",
        "        weight = torch.zeros((s2_series.shape[0], s2_series.shape[1], 1, 1)).to(self.device)\n",
        "\n",
        "        # downsample l8 and s2 to smaller size\n",
        "        if scale_l8 > 1:\n",
        "            l8co_small = torch.nn.functional.interpolate(l8co, scale_factor=1.0/scale_l8, mode='bicubic')\n",
        "        else:\n",
        "            l8co_small = l8co\n",
        "        if scale_s2 > 1:\n",
        "            # change to 4D data for interpolation\n",
        "            s2_series_shape = s2_series.shape\n",
        "            s2_series_small = torch.nn.functional.interpolate(s2_series.reshape((s2_series_shape[0]*s2_series_shape[1], *s2_series_shape[2:])), scale_factor=1.0/scale_s2, mode='bicubic')\n",
        "            s2_series_small = s2_series_small.reshape((*s2_series_shape[:3], int(s2_series_shape[-2]/scale_s2), int(s2_series_shape[-1]/scale_s2)))\n",
        "        else:\n",
        "            s2_series_small = s2_series\n",
        "\n",
        "\n",
        "        # Apply UNet to s2_series\n",
        "        for itime in range(s2_series.shape[1]):\n",
        "            if np.all(mask[:, itime] == True): # all images of this time in this batch are masked\n",
        "                weight[:, itime, ...].fill_(-torch.inf)\n",
        "            else: # there are some images of this time in this batch not masked\n",
        "                weight[:, itime, ...] = self.Fextractor(torch.cat((l8co_small, l8co_small - s2_series_small[:, itime, :, :, :]), dim=1))\n",
        "                weight[:, itime, ...][mask[:, itime]] = -torch.inf\n",
        "        weight_softmax = torch.softmax(weight, dim=1)\n",
        "        weight = weight.unsqueeze(-1).expand(-1, -1, s2_series.shape[-3], s2_series.shape[-2], s2_series.shape[-1])\n",
        "        weight_softmax = weight_softmax.unsqueeze(-1).expand(-1, -1, s2_series.shape[-3], s2_series.shape[-2], s2_series.shape[-1])\n",
        "        return (s2_series*weight_softmax).sum(1), weight_softmax, weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MxXHmvgJFFwj"
      },
      "outputs": [],
      "source": [
        "class SpatiotemporalFusionNetwork(nn.Module):\n",
        "  def __init__(self, d0, d1, d2):\n",
        "    super(SpatiotemporalFusionNetwork, self).__init__()\n",
        "    self.shared_network = nn.Sequential(\n",
        "        nn.Conv2d(1, d0, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(d0, d1, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.ConvTranspose2d(d1, d1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.ConvTranspose2d(d1, d2, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "    # High-frequency extraction stage\n",
        "    self.high_freq_extract = nn.Sequential(\n",
        "        nn.Conv2d(1, d0, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(d0, d1, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(d1, d1, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(d1, d2, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "    # Feature fusion stage\n",
        "    self.fusion = nn.Sequential(\n",
        "        nn.Conv2d(d2, d1, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(d1, d0, kernel_size=1, stride=1, padding=0),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(d0, 1, kernel_size=1, stride=1, padding=0),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, l8_0, l8_k, s2_k):\n",
        "    # goal: predict s2_0\n",
        "\n",
        "    # High-frequency extraction\n",
        "    s2_k_h = self.high_freq_extract(s2_k)   # (batch, d2, 300, 300)\n",
        "    # Feature expansion\n",
        "    l8_0_h = self.shared_network(l8_0)      # (batch, d2, 300, 300)\n",
        "    l8_k_h = self.shared_network(l8_k)      # (batch, d2, 300, 300)\n",
        "    # Feature fusion\n",
        "    s2_0_h = l8_0_h + s2_k_h - l8_k_h       # (batch, d2, 300, 300)\n",
        "    s2_0 = self.fusion(s2_0_h)              # (batch, 1, 300, 300)\n",
        "    return s2_0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RTOJa-JV8gDb"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KP3DaIyi8gDb"
      },
      "outputs": [],
      "source": [
        "class cls_dataset(Dataset):\n",
        "    def __init__(self, hdf5file_path_list, loc_l8, loc_s2, num1, num2) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.set = []\n",
        "\n",
        "        SIZE = 100\n",
        "        for iloc in range(num1, num2, 1):\n",
        "          hdf5_file = h5py.File(hdf5file_path_list[iloc-num1],\"r\")\n",
        "          samples_l8co = torch.Tensor(np.array(hdf5_file[\"l8co\"]))\n",
        "          samples_l8panco = torch.Tensor(np.array(hdf5_file[\"l8panco\"]))\n",
        "          samples_s2co = torch.Tensor(np.array(hdf5_file[\"s2co\"]))\n",
        "          samples_l8 = torch.Tensor(np.array(hdf5_file[\"l8\"]))\n",
        "          samples_l8pan = torch.Tensor(np.array(hdf5_file[\"l8pan\"]))\n",
        "          samples_s2 = torch.Tensor(np.array(hdf5_file[\"s2\"]))\n",
        "          loc_l8 = np.array(hdf5_file[\"l8_pos\"])\n",
        "          loc_l8 = np.array(hdf5_file[\"s2_pos\"])\n",
        "          patch_num = samples_l8co.shape[0]\n",
        "\n",
        "          series_len_l8 = samples_l8.shape[1] + 1\n",
        "          series_len_s2 = samples_s2.shape[1] + 1\n",
        "\n",
        "          samples_l8co = samples_l8co.unsqueeze(1)\n",
        "          l8 = torch.cat((samples_l8[:, :loc_l8[iloc-1]], samples_l8co, samples_l8[:, loc_l8[iloc-1]:]), dim=1)\n",
        "          for iband in range(7):\n",
        "            min_band = 0\n",
        "            scale = 1.0\n",
        "            l8[:, :, iband, :, :] = (l8[:, :, iband, :, :] - min_band) * scale\n",
        "          if series_len_l8 < 6:\n",
        "            zeros_array = torch.zeros((l8.shape[0], 6 - series_len_l8, l8.shape[2], l8.shape[3], l8.shape[4]))\n",
        "            l8_series = torch.cat((l8, zeros_array), dim=1)\n",
        "          else:\n",
        "            l8_series = l8\n",
        "\n",
        "          samples_l8panco = samples_l8panco.unsqueeze(1)\n",
        "          l8pan = torch.cat((samples_l8pan[:, :loc_l8[iloc-1]], samples_l8panco, samples_l8pan[:, loc_l8[iloc-1]:]), dim=1)\n",
        "          if series_len_l8 < 6:\n",
        "            zeros_array = torch.zeros((l8pan.shape[0], 6 - series_len_l8, l8pan.shape[2], l8pan.shape[3], l8pan.shape[4]))\n",
        "            l8pan_series = torch.cat((l8pan, zeros_array), dim=1)\n",
        "          else:\n",
        "            l8pan_series = l8pan\n",
        "\n",
        "          samples_s2co = samples_s2co.unsqueeze(1)\n",
        "          s2 = torch.cat((samples_s2[:, :loc_s2[iloc-1]], samples_s2co, samples_s2[:, loc_s2[iloc-1]:]), dim=1)\n",
        "          for iband in range(12):\n",
        "            min_band = 0\n",
        "            scale = 1e-4\n",
        "            s2[:, :, iband, :, :] = (s2[:, :, iband, :, :] - min_band) * scale\n",
        "          if series_len_s2 < 12:\n",
        "            zeros_array = torch.zeros((s2.shape[0], 12 - series_len_s2, s2.shape[2], s2.shape[3], s2.shape[4]))\n",
        "            s2_series = torch.cat((s2, zeros_array), dim=1)\n",
        "          else:\n",
        "            s2_series = s2\n",
        "\n",
        "          nan_mask = torch.isnan(l8_series)\n",
        "\n",
        "          # Replace NaN values with 0\n",
        "          l8_series[nan_mask] = 0\n",
        "\n",
        "          for idata in range(patch_num):\n",
        "            info_dict = {\n",
        "                'l8': l8_series[idata],\n",
        "                'l8pan': l8pan_series[idata],\n",
        "                's2': s2_series[idata],\n",
        "                'series_len_l8': series_len_l8,\n",
        "                'series_len_s2': series_len_s2,\n",
        "                'loc_l8': loc_l8[iloc-1],\n",
        "                'loc_s2': loc_s2[iloc-1]\n",
        "            }\n",
        "            self.set.append(info_dict)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.set[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hSmXD5Dq8gDb"
      },
      "outputs": [],
      "source": [
        "def load_datasets(num1, num2):\n",
        "\n",
        "    root = 'D:/SR/data/segmented100_v2/'\n",
        "    path_list = []\n",
        "    for iloc in range(num1, num2):\n",
        "      path_list.append(os.path.join(root, f\"loc{iloc}.hdf5\"))\n",
        "\n",
        "    data_set = cls_dataset(hdf5file_path_list=path_list, num1=num1, num2=num2)\n",
        "\n",
        "    print(len(data_set))\n",
        "\n",
        "    return data_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ithUOlmeWat"
      },
      "source": [
        "offset l8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFz1HIljfztw",
        "outputId": "de4e1672-9f27-4131-dcf5-056eb2ede411"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 16\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 50\n",
        "weight_decay = 0.00001\n",
        "\n",
        "\n",
        "data_loader = DataLoader(data_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize the autoencoder\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('using device: ', device)\n",
        "network = SpatiotemporalFusionNetwork(d0=32, d1=64, d2=128)\n",
        "network.to(device)\n",
        "weightnet = ImageWeights(in_dim=7, dim=32, img_size=100, device=device)\n",
        "weightnet.load_state_dict(torch.load('D:/SR/baseline/DCSTFN/model/weightnet/indim7dim32_bs16lr2e-3wd3e-3_epoch100_v6tr1_falseimgs_zerorandommagnifywrongloc_falseimageloss_singleweight/Weightnet.pth'))\n",
        "weightnet.to(device)\n",
        "weightnet.eval()  # Set to evaluation mode to freeze weights\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.MSELoss()  # Mean squared error loss\n",
        "optimizer = optim.Adam(network.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "s2_seven_bands = [0, 1, 2, 3, 8, 10, 11]\n",
        "target_band = [2]\n",
        "target_band_s2 = [2]\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for data_dict in data_loader:\n",
        "        l8, s2 = data_dict['l8'][:, :, target_band], data_dict['s2'][:, :, target_band_s2]\n",
        "        l8_fullband, s2_sevenband = data_dict['l8'], data_dict['s2'][:, :, s2_seven_bands]\n",
        "\n",
        "        l8, s2 = l8.to(device), s2.to(device)\n",
        "        l8_fullband, s2_sevenband = l8_fullband.to(device), s2_sevenband.to(device)\n",
        "\n",
        "        l8_time_num, s2_time_num = data_dict['series_len_l8'], data_dict['series_len_s2']\n",
        "        l8_loc, s2_loc = data_dict['loc_l8'], data_dict['loc_s2']\n",
        "\n",
        "        shape_l8, shape_s2 = l8.shape, s2.shape\n",
        "\n",
        "\n",
        "\n",
        "        ################################## second part of gradient descent ##########################################\n",
        "        # third loss: Time Series Inference Loss\n",
        "        l8 = l8.reshape((shape_l8[0]*shape_l8[1], shape_l8[2], shape_l8[3], shape_l8[4]))\n",
        "        s2 = s2.reshape((shape_s2[0]*shape_s2[1], shape_s2[2], shape_s2[3], shape_s2[4]))\n",
        "        ind_l8 = []\n",
        "        for i in range(batch_size):\n",
        "            if l8_loc[i] < l8_time_num[i]-1:\n",
        "                ind_l8.append(int(i*shape_l8[1] + l8_loc[i] + 1))\n",
        "            else:\n",
        "                ind_l8.append(int(i*shape_l8[1] + l8_loc[i] - 1))\n",
        "        ind_s2 = [int(i*shape_s2[1] + s2_loc[i]) for i in range(batch_size)]\n",
        "        ind_s2_neighbor = [int(i*shape_s2[1] + s2_loc[i] + 1) for i in range(batch_size)]\n",
        "        l8_co = l8[ind_l8]\n",
        "        s2_co = s2[ind_s2]\n",
        "        \n",
        "        l8_fullband_co = l8_fullband.reshape((shape_l8[0]*shape_l8[1], l8_fullband.shape[2], shape_l8[3], shape_l8[4]))[ind_l8]\n",
        "        # create mask for weight\n",
        "        s2_series_mask = np.empty((shape_s2[0], shape_s2[1]), dtype=bool)\n",
        "        s2_series_mask[:] = False\n",
        "        for ibatch in range(s2_series_mask.shape[0]):\n",
        "            s2_series_mask[ibatch, s2_time_num[ibatch]:] = True     # mask empty images\n",
        "            s2_series_mask[ibatch, s2_loc[ibatch]] = True   # mask gt s2 image\n",
        "        s2_p, s2_weightsm, _ = weightnet(l8_fullband_co, s2_sevenband, s2_series_mask)\n",
        "        s2_p = s2_p[:, target_band, ...]\n",
        "        \n",
        "        \n",
        "        s2_neighbor = s2_p\n",
        "        l8_neighbor = torch.nn.functional.interpolate(s2_neighbor, scale_factor=75.0/300.0, mode='bicubic')\n",
        "        l8_co = torch.nn.functional.interpolate(l8_co, scale_factor=75.0/100.0, mode='bicubic')\n",
        "        s2 = s2.reshape(shape_s2)\n",
        "        l8 = l8.reshape(shape_l8)\n",
        "\n",
        "        s2_p = network(l8_co, l8_neighbor, s2_neighbor)\n",
        "\n",
        "\n",
        "        loss = criterion(s2_co, s2_p)\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.7f}')\n",
        "    # Save the trained model\n",
        "folder_path = f'./model/fullres/timeseriess2/l8offset_d32d64d128_bs16lr1e-4wd1e-5_epoch50'\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "weightnet_path = os.path.join(folder_path, 'band{}.pth'.format(target_band))\n",
        "torch.save(network.state_dict(), weightnet_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX1oPRtsGkUT"
      },
      "source": [
        "real l8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYutvoovLPLk",
        "outputId": "63bea1dc-4d7c-4092-9673-8f43f5019d3e"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 16\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 50\n",
        "weight_decay = 0.00001\n",
        "\n",
        "\n",
        "data_loader = DataLoader(data_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize the autoencoder\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('using device: ', device)\n",
        "network = SpatiotemporalFusionNetwork(d0=32, d1=64, d2=128)\n",
        "network.to(device)\n",
        "weightnet = ImageWeights(in_dim=7, dim=32, img_size=100, device=device)\n",
        "weightnet.load_state_dict(torch.load('D:/SR/baseline/DCSTFN/model/weightnet/indim7dim32_bs16lr2e-3wd3e-3_epoch100_v6tr1_falseimgs_zerorandommagnifywrongloc_falseimageloss_singleweight/Weightnet.pth'))\n",
        "weightnet.to(device)\n",
        "weightnet.eval()  # Set to evaluation mode to freeze weights\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.MSELoss()  # Mean squared error loss\n",
        "optimizer = optim.Adam(network.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "s2_seven_bands = [0, 1, 2, 3, 8, 10, 11]\n",
        "target_band = [2]\n",
        "target_band_s2 = [2]\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for data_dict in data_loader:\n",
        "        l8, s2 = data_dict['l8'][:, :, target_band], data_dict['s2'][:, :, target_band_s2]\n",
        "        l8_fullband, s2_sevenband = data_dict['l8'], data_dict['s2'][:, :, s2_seven_bands]\n",
        "\n",
        "        l8, s2 = l8.to(device), s2.to(device)\n",
        "        l8_fullband, s2_sevenband = l8_fullband.to(device), s2_sevenband.to(device)\n",
        "\n",
        "        l8_time_num, s2_time_num = data_dict['series_len_l8'], data_dict['series_len_s2']\n",
        "        l8_loc, s2_loc = data_dict['loc_l8'], data_dict['loc_s2']\n",
        "\n",
        "        shape_l8, shape_s2 = l8.shape, s2.shape\n",
        "\n",
        "\n",
        "\n",
        "        ################################## second part of gradient descent ##########################################\n",
        "        # third loss: Time Series Inference Loss\n",
        "        l8 = l8.reshape((shape_l8[0]*shape_l8[1], shape_l8[2], shape_l8[3], shape_l8[4]))\n",
        "        s2 = s2.reshape((shape_s2[0]*shape_s2[1], shape_s2[2], shape_s2[3], shape_s2[4]))\n",
        "        ind_l8 = [int(i*shape_l8[1] + l8_loc[i]) for i in range(batch_size)]\n",
        "        ind_s2 = [int(i*shape_s2[1] + s2_loc[i]) for i in range(batch_size)]\n",
        "        ind_s2_neighbor = [int(i*shape_s2[1] + s2_loc[i] + 1) for i in range(batch_size)]\n",
        "        l8_co = l8[ind_l8]\n",
        "        s2_co = s2[ind_s2]\n",
        "        \n",
        "        \n",
        "        \n",
        "        l8_fullband_co = l8_fullband.reshape((shape_l8[0]*shape_l8[1], l8_fullband.shape[2], shape_l8[3], shape_l8[4]))[ind_l8]\n",
        "        # create mask for weight\n",
        "        s2_series_mask = np.empty((shape_s2[0], shape_s2[1]), dtype=bool)\n",
        "        s2_series_mask[:] = False\n",
        "        for ibatch in range(s2_series_mask.shape[0]):\n",
        "            s2_series_mask[ibatch, s2_time_num[ibatch]:] = True     # mask empty images\n",
        "            s2_series_mask[ibatch, s2_loc[ibatch]] = True   # mask gt s2 image\n",
        "        s2_p, s2_weightsm, _ = weightnet(l8_fullband_co, s2_sevenband, s2_series_mask)\n",
        "        s2_p = s2_p[:, target_band, ...]\n",
        "        \n",
        "        \n",
        "        s2_neighbor = s2_p\n",
        "        l8_neighbor = torch.nn.functional.interpolate(s2_neighbor, scale_factor=75.0/300.0, mode='bicubic')\n",
        "        l8_co = torch.nn.functional.interpolate(l8_co, scale_factor=75.0/100.0, mode='bicubic')\n",
        "        s2 = s2.reshape(shape_s2)\n",
        "        l8 = l8.reshape(shape_l8)\n",
        "        \n",
        "\n",
        "        s2_p = network(l8_co, l8_neighbor, s2_neighbor)\n",
        "\n",
        "\n",
        "        loss = criterion(s2_co, s2_p)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.7f}')\n",
        "    # Save the trained model\n",
        "folder_path = f'./model/fullres/timeseriess2/d32d64d128_bs16lr1e-4wd1e-5_epoch50'\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "weightnet_path = os.path.join(folder_path, 'band{}.pth'.format(target_band))\n",
        "torch.save(network.state_dict(), weightnet_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DuEGHhxRjSA"
      },
      "source": [
        "downsample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXsTbyiIQ582",
        "outputId": "b74ba878-c444-4360-aa30-2fa69e316fcf"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 16\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 50\n",
        "weight_decay = 0.00001\n",
        "\n",
        "\n",
        "data_loader = DataLoader(data_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize the autoencoder\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('using device: ', device)\n",
        "network = SpatiotemporalFusionNetwork(d0=32, d1=64, d2=128)\n",
        "network.to(device)\n",
        "weightnet = ImageWeights(in_dim=7, dim=32, img_size=100, device=device)\n",
        "weightnet.load_state_dict(torch.load('D:/SR/baseline/DCSTFN/model/weightnet/indim7dim32_bs16lr2e-3wd3e-3_epoch100_v6tr1_falseimgs_zerorandommagnifywrongloc_falseimageloss_singleweight/Weightnet.pth'))\n",
        "weightnet.to(device)\n",
        "weightnet.eval()  # Set to evaluation mode to freeze weights\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.MSELoss()  # Mean squared error loss\n",
        "# criterion = nn.L1Loss()  # Mean absolute error loss\n",
        "optimizer = optim.Adam(network.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "s2_seven_bands = [0, 1, 2, 3, 8, 10, 11]\n",
        "target_band = [2]\n",
        "target_band_s2 = [2]\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for data_dict in data_loader:\n",
        "        l8, s2 = data_dict['l8'][:, :, target_band], data_dict['s2'][:, :, target_band_s2]\n",
        "        l8_fullband, s2_sevenband = data_dict['l8'], data_dict['s2'][:, :, s2_seven_bands]\n",
        "\n",
        "        l8, s2 = l8.to(device), s2.to(device)\n",
        "        l8_fullband, s2_sevenband = l8_fullband.to(device), s2_sevenband.to(device)\n",
        "\n",
        "        l8_time_num, s2_time_num = data_dict['series_len_l8'], data_dict['series_len_s2']\n",
        "        l8_loc, s2_loc = data_dict['loc_l8'], data_dict['loc_s2']\n",
        "\n",
        "        shape_l8, shape_s2 = l8.shape, s2.shape\n",
        "\n",
        "\n",
        "\n",
        "        ################################## second part of gradient descent ##########################################\n",
        "        # third loss: Time Series Inference Loss\n",
        "        s2 = s2.reshape((shape_s2[0]*shape_s2[1], shape_s2[2], shape_s2[3], shape_s2[4]))\n",
        "        ind_s2 = [int(i*shape_s2[1] + s2_loc[i]) for i in range(batch_size)]\n",
        "        ind_s2_fakegt = [int(i*shape_s2[1] + s2_loc[i] - 1) for i in range(batch_size)]\n",
        "        ind_s2_neighbor = [int(i*shape_s2[1] + s2_loc[i] + 1) for i in range(batch_size)]\n",
        "        s2_co = s2[ind_s2]\n",
        "        \n",
        "        l8_fullband_co = l8_fullband.reshape((shape_l8[0]*shape_l8[1], l8_fullband.shape[2], shape_l8[3], shape_l8[4]))[ind_l8]\n",
        "        # create mask for weight\n",
        "        s2_series_mask = np.empty((shape_s2[0], shape_s2[1]), dtype=bool)\n",
        "        s2_series_mask[:] = False\n",
        "        for ibatch in range(s2_series_mask.shape[0]):\n",
        "            s2_series_mask[ibatch, s2_time_num[ibatch]:] = True     # mask empty images\n",
        "            s2_series_mask[ibatch, s2_loc[ibatch]] = True   # mask gt s2 image\n",
        "        s2_p, s2_weightsm, _ = weightnet(l8_fullband_co, s2_sevenband, s2_series_mask)\n",
        "        s2_p = s2_p[:, target_band, ...]\n",
        "        \n",
        "        \n",
        "        s2_fakegt = s2_p\n",
        "        l8_co = torch.nn.functional.interpolate(s2_fakegt, scale_factor=75.0/300.0, mode='bicubic')\n",
        "        s2_neighbor = s2[ind_s2_neighbor]\n",
        "        l8_neighbor = torch.nn.functional.interpolate(s2_neighbor, scale_factor=75.0/300.0, mode='bicubic')\n",
        "        s2 = s2.reshape(shape_s2)\n",
        "\n",
        "        s2_p = network(l8_co, l8_neighbor, s2_neighbor)\n",
        "\n",
        "\n",
        "        loss = criterion(s2_co, s2_p)\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.7f}')\n",
        "# Save the trained model\n",
        "folder_path = f'./model/fullres/timeseriess2/l8downsamp_d32d64d128_bs16lr1e-4wd1e-5_epoch50'\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "weightnet_path = os.path.join(folder_path, 'band{}.pth'.format(target_band))\n",
        "torch.save(network.state_dict(), weightnet_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "jPJsN3s28gDd"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "testmodel_list = []\n",
        "for target_band in [[3],[2],[1]]:\n",
        "# for target_band in [[6],[5],[4]]:\n",
        "    # folder_path = f'./model/fullres/timeseriess2/d32d64d128_bs16lr1e-4wd1e-5_epoch50'\n",
        "    # folder_path = f'./model/fullres/timeseriess2/l8offset_d32d64d128_bs16lr1e-4wd1e-5_epoch50'\n",
        "    folder_path = f'./model/fullres/timeseriess2/l8downsamp_d32d64d128_bs16lr1e-4wd1e-5_epoch50'\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "    network_path = os.path.join(folder_path, 'band{}.pth'.format(target_band))\n",
        "\n",
        "    testmodel = SpatiotemporalFusionNetwork(d0=32, d1=64, d2=128)\n",
        "    testmodel.load_state_dict(torch.load(network_path))\n",
        "    testmodel.to(device)\n",
        "    testmodel.eval()\n",
        "    testmodel_list.append(testmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "eh8ogRdpBlEM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkjqTOaVf-U4"
      },
      "source": [
        "original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huOmg7wZ8gDd"
      },
      "outputs": [],
      "source": [
        "s2_seven_bands = [0, 1, 2, 3, 8, 10, 11]\n",
        "RGB = [[3],[2],[1]]\n",
        "RGB_s2 = [[3], [2], [1]]\n",
        "\n",
        "\n",
        "flag = False\n",
        "i = 0\n",
        "with torch.no_grad():\n",
        "    for iloc in range(70, 101):\n",
        "        print(f'iloc{iloc}')\n",
        "        test_dataset = load_datasets(iloc, iloc+1)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False) # donot shuffle\n",
        "        for iimg, data_dict in enumerate(test_loader):\n",
        "            img_l8_p_SR = []\n",
        "            img_l8_co = []\n",
        "            img_s2_co = []\n",
        "            for imodel, target_band in enumerate(RGB):\n",
        "                target_band_s2 = RGB_s2[imodel]\n",
        "                l8, s2 = data_dict['l8'][:, :, target_band], data_dict['s2'][:, :, target_band_s2]\n",
        "\n",
        "                l8, s2 = l8.to(device), s2.to(device)\n",
        "\n",
        "                l8_time_num, s2_time_num = data_dict['series_len_l8'], data_dict['series_len_s2']\n",
        "                l8_loc, s2_loc = data_dict['loc_l8'], data_dict['loc_s2']\n",
        "\n",
        "                shape_l8, shape_s2 = l8.shape, s2.shape\n",
        "\n",
        "\n",
        "                l8 = l8.reshape((shape_l8[0]*shape_l8[1], shape_l8[2], shape_l8[3], shape_l8[4]))\n",
        "                s2 = s2.reshape((shape_s2[0]*shape_s2[1], shape_s2[2], shape_s2[3], shape_s2[4]))\n",
        "                l8_co = l8[l8_loc]\n",
        "                s2_co = s2[s2_loc]\n",
        "                s2_neighbor = s2[s2_loc[0] + 1].unsqueeze(0)\n",
        "                l8_neighbor = torch.nn.functional.interpolate(s2_neighbor, scale_factor=75.0/300.0, mode='bicubic')\n",
        "                l8_co = torch.nn.functional.interpolate(l8_co, scale_factor=75.0/100.0, mode='bicubic')\n",
        "                s2 = s2.reshape(shape_s2)\n",
        "                l8 = l8.reshape(shape_l8)\n",
        "\n",
        "                l8_p_SR = testmodel_list[imodel](l8_co, l8_neighbor, s2_neighbor)\n",
        "\n",
        "\n",
        "                l8_p_SR = np.array(l8_p_SR.cpu()).squeeze(0)\n",
        "\n",
        "                l8_p_SR = (l8_p_SR + 0) * 255\n",
        "                l8_p_SR = l8_p_SR.clip(0, 255)\n",
        "                \n",
        "\n",
        "\n",
        "                img_l8_p_SR.append(l8_p_SR) # l8_p_SR: (1, 300, 300)\n",
        "\n",
        "            img_l8_p_SR = np.concatenate(img_l8_p_SR, axis=0)\n",
        "            img_l8_p_SR = img_l8_p_SR.transpose((1,2,0)).astype(np.uint8) # shape: (3, 300, 300)\n",
        "            \n",
        "            # output_folder_l8_p_SR = 'D:/SR/result/DCSTFN_fullres_timeseriess2/DCSTFN_l8s2_ifr'\n",
        "            # output_folder_l8_p_SR = 'D:/SR/result/DCSTFN_fullres_timeseriess2/DCSTFN_nl8s2_ifr'\n",
        "            # output_folder_l8_p_SR = 'D:/SR/result/DCSTFN_fullres_timeseriess2/DCSTFN_intrpl8s2_ifr'\n",
        "            output_folder_l8_p_SR = 'D:/SR/result/DCSTFN_fullres_timeseriess2/DCSTFN_ds2s2_ifr'\n",
        "            if not os.path.exists(output_folder_l8_p_SR):\n",
        "                # Create the folder\n",
        "                os.makedirs(output_folder_l8_p_SR)\n",
        "                print(f\"Folder '{output_folder_l8_p_SR}' created.\")\n",
        "            # else:\n",
        "            #     print(f\"Folder '{output_folder_l8_p_SR}' already exists.\")\n",
        "            output_path_l8_p_SR = os.path.join(output_folder_l8_p_SR, f'loc{iloc}_{iimg}.png')\n",
        "            cv2.imwrite(output_path_l8_p_SR, img_l8_p_SR)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
